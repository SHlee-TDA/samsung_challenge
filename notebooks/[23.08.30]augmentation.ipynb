{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== System Information ==========\n",
      "DATE : 2023-08-31\n",
      "Pyton Version : 3.10.12\n",
      "PyTorch Version : 2.0.1\n",
      "OS : Linux 5.15.0-78-generic\n",
      "CPU spec : x86_64\n",
      "RAM spec : 122.84 GB\n",
      "Device 0:\n",
      "Name: NVIDIA GeForce RTX 3090\n",
      "Total Memory: 24576.0 MB\n",
      "Driver Version: 530.41.03\n",
      "==============================\n",
      "Device 1:\n",
      "Name: NVIDIA GeForce RTX 3090\n",
      "Total Memory: 24576.0 MB\n",
      "Driver Version: 530.41.03\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.tools.print_sysinfo import print_env\n",
    "print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from src.tools.rle_encoder import rle_encode\n",
    "from src.data.dataset import SourceDataset, TargetDataset\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "def fisheye_circular_transform_torch(image, mask=None, fov_degree=200, focal_scale=4.5):\n",
    "    _, h, w = image.shape\n",
    "    \n",
    "    # Convert degrees to radians using torch tensor\n",
    "    radian_conversion = torch.tensor(np.pi/180, dtype=image.dtype, device=image.device)\n",
    "    \n",
    "    \n",
    "    # Calculate the focal length using the given FOV\n",
    "    f = w / (2 * torch.tan(0.5 * fov_degree * radian_conversion))\n",
    "    f_scaled = f * focal_scale\n",
    "    \n",
    "    # Meshgrid for coordinates\n",
    "    x = torch.linspace(-w//2, w//2, w).repeat(h, 1)\n",
    "    y = torch.linspace(-h//2, h//2, h).unsqueeze(1).repeat(1, w)\n",
    "    r = torch.sqrt(x*x + y*y)\n",
    "    theta = torch.atan2(y, x)\n",
    "    \n",
    "    # Apply fisheye transformation\n",
    "    r_fisheye = f_scaled * torch.atan(r / f_scaled)\n",
    "    x_fisheye = (w // 2 + r_fisheye * torch.cos(theta)).long()\n",
    "    y_fisheye = (h // 2 + r_fisheye * torch.sin(theta)).long()\n",
    "    \n",
    "    # Create masks for valid coordinates\n",
    "    valid_coords = (x_fisheye >= 0) & (x_fisheye < w) & (y_fisheye >= 0) & (y_fisheye < h)\n",
    "    \n",
    "    # Initialize output images\n",
    "    new_image = torch.zeros_like(image)\n",
    "    if mask is not None:\n",
    "        new_mask = torch.zeros_like(mask)\n",
    "    else:\n",
    "        new_mask = None\n",
    "    \n",
    "    # Assign values\n",
    "    new_image[:, valid_coords] = image[:, y_fisheye[valid_coords], x_fisheye[valid_coords]]\n",
    "    if mask is not None:\n",
    "        new_mask[:, valid_coords] = mask[:, y_fisheye[valid_coords], x_fisheye[valid_coords]]\n",
    "    \n",
    "    return new_image, new_mask\n",
    "\n",
    "class FisheyeTransform(ImageOnlyTransform):\n",
    "    def __init__(self, fov_degree=200, focal_scale=4.5, always_apply=False, p=1.0):\n",
    "        super(FisheyeTransform, self).__init__(always_apply, p)\n",
    "        self.fov_degree = fov_degree\n",
    "        self.focal_scale = focal_scale\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        image_tensor = torch.tensor(image).permute(2, 0, 1).float()\n",
    "        transformed_image, _ = fisheye_circular_transform_torch(image_tensor, fov_degree=self.fov_degree, focal_scale=self.focal_scale)\n",
    "        return transformed_image.permute(1, 2, 0).byte().numpy()\n",
    "\n",
    "    def apply_to_mask(self, mask, **params):\n",
    "        mask_tensor = torch.tensor(mask).unsqueeze(0).float()\n",
    "        _, transformed_mask = fisheye_circular_transform_torch(mask_tensor, fov_degree=self.fov_degree, focal_scale=self.focal_scale)\n",
    "        return transformed_mask.squeeze(0).byte().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(always_apply=True),\n",
    "        OneOf([\n",
    "            GaussNoise(always_apply=True),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            MotionBlur(p=0.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1, always_apply=True),\n",
    "            Blur(blur_limit=3, p=0.1, always_apply=True),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=0.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=0.1),\n",
    "            PiecewiseAffine(p=0.3),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            Sharpen(always_apply=True, p=1.0),\n",
    "            Emboss(always_apply=True, p=1.0),\n",
    "            RandomBrightnessContrast(always_apply=True, p=1.0),\n",
    "        ], p=0.3),\n",
    "        HueSaturationValue(always_apply=True, p=1.0),\n",
    "        FisheyeAug(k=0.5, p=1.0),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    "    return Compose(train_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = A.Compose(\n",
    "    [\n",
    "        FisheyeTransform(p=0.2),\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "#augmentation = get_training_augmentation()\n",
    "\n",
    "\n",
    "train_dataset = SourceDataset(csv_file='train_source.csv', transform=augmentation, is_training=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "valid_dataset = SourceDataset(csv_file='val_source.csv', transform=transform, is_training=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class FPN_UNet_Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FPN_UNet_Dropout, self).__init__()\n",
    "\n",
    "        # Encoder (Downsampling path)\n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dropout1 = nn.Dropout(0.5)  # 추가된 Dropout 레이어\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)  # 추가된 Dropout 레이어\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dropout3 = nn.Dropout(0.5)  # 추가된 Dropout 레이어\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "        self.dropout4 = nn.Dropout(0.5)  # 추가된 Dropout 레이어\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Upward path and lateral connections for FPN\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.lateral3 = nn.Conv2d(256, 256, kernel_size=1)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.lateral2 = nn.Conv2d(128, 128, kernel_size=1)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.lateral1 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        \n",
    "        # FPN heads for each pyramid level\n",
    "        self.fpn_out3 = nn.Conv2d(256, 13, kernel_size=3, padding=1)\n",
    "        self.fpn_out2 = nn.Conv2d(128, 13, kernel_size=3, padding=1)\n",
    "        self.fpn_out1 = nn.Conv2d(64, 13, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(self.dropout1(conv1))  # Dropout 적용\n",
    "        \n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(self.dropout2(conv2))  # Dropout 적용\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(self.dropout3(conv3))  # Dropout 적용\n",
    "        \n",
    "        x = self.dropout4(self.dconv_down4(x))  # Dropout 적용\n",
    "\n",
    "        \n",
    "        # Upward path with lateral connections\n",
    "        x = self.upconv3(x)\n",
    "        conv3 = self.lateral3(conv3)\n",
    "        p3 = torch.add(x, conv3)  # Element-wise addition\n",
    "        out3 = self.fpn_out3(p3)\n",
    "        \n",
    "        x = self.upconv2(p3)\n",
    "        conv2 = self.lateral2(conv2)\n",
    "        p2 = torch.add(x, conv2)\n",
    "        out2 = self.fpn_out2(p2)\n",
    "        \n",
    "        x = self.upconv1(p2)\n",
    "        conv1 = self.lateral1(conv1)\n",
    "        p1 = torch.add(x, conv1)\n",
    "        out1 = self.fpn_out1(p1)\n",
    "        \n",
    "        # Note: You can return combined results or individual FPN layer outputs based on the use case.\n",
    "        return out1, out2, out3\n",
    "\n",
    "class FPN_UNet_FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FPN_UNet_FC, self).__init__()\n",
    "        self.fpn_unet = FPN_UNet_Dropout()\n",
    "        self.upsample = nn.Upsample(size=(224, 224), mode='bilinear', align_corners=True)\n",
    "        self.conv1x1 = nn.Conv2d(13+13+13, 13, kernel_size=1)  # Assuming we're concatenating\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1, out2, out3 = self.fpn_unet(x)\n",
    "\n",
    "        # Upsample each output to the desired size: 224x224\n",
    "        out1_upsampled = self.upsample(out1)\n",
    "        out2_upsampled = self.upsample(out2)\n",
    "        out3_upsampled = self.upsample(out3)\n",
    "\n",
    "        # Concatenate the outputs along the channel dimension\n",
    "        merged_output = torch.cat([out1_upsampled, out2_upsampled, out3_upsampled], dim=1)\n",
    "\n",
    "        # Map to desired number of channels using 1x1 convolution\n",
    "        final_output = self.conv1x1(merged_output)\n",
    "\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_iou(pred, target, num_classes):\n",
    "    iou_list = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "\n",
    "    # For classes excluding the background\n",
    "    for cls in range(num_classes - 1):  # We subtract 1 to exclude the background class\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds[target_inds]).sum().float()\n",
    "        union = (pred_inds + target_inds).sum().float()\n",
    "        if union == 0:\n",
    "            iou_list.append(float('nan'))  # If there is no ground truth, do not include in evaluation\n",
    "        else:\n",
    "            iou_list.append((intersection / union).item())\n",
    "    return iou_list\n",
    "\n",
    "def compute_mIoU(preds, labels, num_classes=13):\n",
    "    iou_list = compute_iou(preds, labels, num_classes)\n",
    "    valid_iou_list = [iou for iou in iou_list if not math.isnan(iou)]\n",
    "    mIoU = sum(valid_iou_list) / len(valid_iou_list)\n",
    "    return mIoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:04<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 1.7846, Training mIoU: 0.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, mIoU: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:03<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Training Loss: 0.8554, Training mIoU: 0.2178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, mIoU: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:06<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Training Loss: 0.6967, Training mIoU: 0.2516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, mIoU: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:06<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Training Loss: 0.5998, Training mIoU: 0.2899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, mIoU: 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:02<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Training Loss: 0.5297, Training mIoU: 0.3376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, mIoU: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:12<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Training Loss: 0.4748, Training mIoU: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, mIoU: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:09<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Training Loss: 0.4452, Training mIoU: 0.3939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, mIoU: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Training Loss: 0.4138, Training mIoU: 0.4159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, mIoU: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:03<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Training Loss: 0.4055, Training mIoU: 0.4220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, mIoU: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:04<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Training Loss: 0.3680, Training mIoU: 0.4474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, mIoU: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:07<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Training Loss: 0.3388, Training mIoU: 0.4661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, mIoU: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Training Loss: 0.3342, Training mIoU: 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, mIoU: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:06<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Training Loss: 0.3338, Training mIoU: 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, mIoU: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Training Loss: 0.3247, Training mIoU: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, mIoU: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:05<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Training Loss: 0.3255, Training mIoU: 0.4737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, mIoU: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Training Loss: 0.3261, Training mIoU: 0.4765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, mIoU: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:06<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Training Loss: 0.3178, Training mIoU: 0.4799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, mIoU: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:04<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Training Loss: 0.3189, Training mIoU: 0.4797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, mIoU: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:03<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Training Loss: 0.3113, Training mIoU: 0.4837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, mIoU: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Training Loss: 0.3129, Training mIoU: 0.4829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, mIoU: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:05<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Training Loss: 0.3061, Training mIoU: 0.4876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, mIoU: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:04<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Training Loss: 0.3073, Training mIoU: 0.4872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, mIoU: 0.0098\n",
      "Early stopping triggered!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "# 1. 모델 불러오기\n",
    "model = FPN_UNet_FC()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "else:\n",
    "    print(f\"Using CPU\")\n",
    "model.to(device)\n",
    "\n",
    "# 2. 데이터 준비 (여기서는 간략하게 표현합니다)\n",
    "#train_loader, val_loader = prepare_target_domain_dataloaders()\n",
    "\n",
    "# 3. 학습 설정\n",
    "criterion = nn.CrossEntropyLoss() # 예시로 CrossEntropyLoss를 사용합니다\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 작은 learning rate 사용\n",
    "\n",
    "# Learning rate scheduler 설정\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "# 4. 학습\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "train_mIoUs = []\n",
    "val_mIoUs = []\n",
    "\n",
    "# Early stopping 관련 설정\n",
    "patience = 20  # 10번의 epoch 동안 성능 향상이 없을 경우 학습 중단\n",
    "no_improve_epochs = 0  # 성능 향상이 없는 epoch의 횟수\n",
    "best_mIoU = 0.0  # 최고의 검증 mIoU 저장\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    num_batches = 0\n",
    "    num_images = 0\n",
    "    \n",
    "    for images, masks in tqdm(train_loader):\n",
    "        \n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "        num_images += images.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += num_images * loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_iou += compute_mIoU(predicted, masks)\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_images\n",
    "    avg_train_mIoU = total_iou / num_images\n",
    "    train_losses.append(avg_loss)\n",
    "    train_mIoUs.append(avg_train_mIoU)\n",
    "    print(f\"Epoch {epoch + 1} - Training Loss: {avg_loss:.4f}, Training mIoU: {avg_train_mIoU:.4f}\")\n",
    "\n",
    "    \n",
    "    # 5. 검증 (간략하게 표현)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_iou = 0\n",
    "        num_images = 0\n",
    "        for images, masks in tqdm(valid_loader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "        \n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_iou += compute_mIoU(predicted, masks)\n",
    "            num_images += images.size(0)\n",
    "        avg_mIoU = total_iou / num_images\n",
    "        print(f\"Epoch {epoch + 1}, mIoU: {avg_mIoU:.4f}\")\n",
    "\n",
    "\n",
    "    # 학습률 업데이트\n",
    "    scheduler.step()\n",
    "\n",
    "    \n",
    "    # Early stopping 검사\n",
    "    if avg_mIoU > best_mIoU:\n",
    "        best_mIoU = avg_mIoU\n",
    "        # 최적의 모델 저장\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            # 최적의 모델 불러오기\n",
    "            model.load_state_dict(torch.load('best_model.pth'))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TargetDataset(csv_file='./test.csv', transform=transform, is_training=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:46<00:00,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_dataloader):\n",
    "        images = images.float().to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "        # batch에 존재하는 각 이미지에 대해서 반복\n",
    "        for pred in outputs:\n",
    "            pred = pred.astype(np.int32)\n",
    "            pred = Image.fromarray(pred) # 이미지로 변환\n",
    "            pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "            pred = np.array(pred) # 다시 수치로 변환\n",
    "            # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "            for class_id in range(12):\n",
    "                class_mask = (pred == class_id).astype(np.int32)\n",
    "                if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "                    mask_rle = rle_encode(class_mask)\n",
    "                    result.append(mask_rle)\n",
    "                else: # 마스크가 존재하지 않는 경우 -1\n",
    "                    result.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mask_rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000_class_0</td>\n",
       "      <td>69871 4 69884 17 70831 4 70844 17 71791 4 7180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0000_class_1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0000_class_2</td>\n",
       "      <td>1 111 725 17 747 325 1685 17 1707 317 2680 25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0000_class_3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0000_class_4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22771</th>\n",
       "      <td>TEST_1897_class_7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22772</th>\n",
       "      <td>TEST_1897_class_8</td>\n",
       "      <td>104 540 648 150 858 17 1064 540 1608 150 1818 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22773</th>\n",
       "      <td>TEST_1897_class_9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22774</th>\n",
       "      <td>TEST_1897_class_10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22775</th>\n",
       "      <td>TEST_1897_class_11</td>\n",
       "      <td>798 4 1758 4 2722 9 3682 9 4642 9 5598 9 6558 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                           mask_rle\n",
       "0       TEST_0000_class_0  69871 4 69884 17 70831 4 70844 17 71791 4 7180...\n",
       "1       TEST_0000_class_1                                                 -1\n",
       "2       TEST_0000_class_2  1 111 725 17 747 325 1685 17 1707 317 2680 25 ...\n",
       "3       TEST_0000_class_3                                                 -1\n",
       "4       TEST_0000_class_4                                                 -1\n",
       "...                   ...                                                ...\n",
       "22771   TEST_1897_class_7                                                 -1\n",
       "22772   TEST_1897_class_8  104 540 648 150 858 17 1064 540 1608 150 1818 ...\n",
       "22773   TEST_1897_class_9                                                 -1\n",
       "22774  TEST_1897_class_10                                                 -1\n",
       "22775  TEST_1897_class_11  798 4 1758 4 2722 9 3682 9 4642 9 5598 9 6558 ...\n",
       "\n",
       "[22776 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "submit['mask_rle'] = result\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./augmentation_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
